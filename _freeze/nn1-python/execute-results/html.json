{
  "hash": "af12379c424672064d7d3ef622bc491a",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Feedforward Neural Network - Python\"\nformat:\n  html:\n    code-fold: false\n  pdf:\n    toc: true\njupyter: python3\n---\n\n## Feedforward Neural Network (MLP) Using Ames Housing (Python)\n\nThis chapter fits a feed-forward neural network to the Ame Housing subset used in the R version.  \nRMSE is computed manually for compatibility with older scikit-learn versions.\n\n---\n\n### 1. Load and Prepare Data\n\n::: {#21405e06 .cell execution_count=2}\n``` {.python .cell-code}\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.datasets import fetch_openml\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.metrics import mean_squared_error\n\nnp.random.seed(12345)\n\names = fetch_openml(name=\"house_prices\", as_frame=True)\ndf = ames.frame\n\nselected_cols = [\n    \"SalePrice\",\"BedroomAbvGr\",\"YearBuilt\",\"MoSold\",\"LotArea\",\n    \"Street\",\"CentralAir\",\"1stFlrSF\",\"2ndFlrSF\",\"FullBath\",\n    \"HalfBath\",\"Fireplaces\",\"GarageArea\",\"GrLivArea\",\"TotRmsAbvGrd\"\n]\n\ndf_sub = df[selected_cols].dropna()\ndf_sub = pd.get_dummies(df_sub, columns=[\"Street\",\"CentralAir\"], drop_first=True)\n\ny = df_sub[\"SalePrice\"]\nX = df_sub.drop(\"SalePrice\", axis=1)\n```\n:::\n\n\n---\n\n### 2. Train/Test Split & Scaling\n\n::: {#9b839249 .cell execution_count=3}\n``` {.python .cell-code}\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=12345\n)\n\nscaler = StandardScaler()\nscaler.fit(X_train)\n\nX_train_s = scaler.transform(X_train)\nX_test_s = scaler.transform(X_test)\n```\n:::\n\n\n---\n\n### 3. Simple MLP Model\n\n::: {#f1b1e103 .cell execution_count=4}\n``` {.python .cell-code}\nnn_simple = MLPRegressor(\n    solver=\"lbfgs\",\n    alpha=1e-5,\n    hidden_layer_sizes=(5,),\n    random_state=12345,\n    max_iter=5000\n)\n\nnn_simple.fit(X_train_s, y_train)\npred_simple = nn_simple.predict(X_test_s)\n\nrmse_simple = mean_squared_error(y_test, pred_simple) ** 0.5\nrmse_simple\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```\n38907.904754996634\n```\n:::\n:::\n\n\n---\n\n### 4. Grid Search Tuning\n\n::: {#115fe243 .cell execution_count=5}\n``` {.python .cell-code}\nparam_grid = {\n    \"hidden_layer_sizes\": [(h,) for h in [3,4,5,6,7]],\n    \"alpha\": [0.00005,0.0005],\n    \"solver\": [\"lbfgs\"]\n}\n\nnn_base = MLPRegressor(max_iter=5000, random_state=12345)\n\ngrid = GridSearchCV(\n    estimator=nn_base,\n    param_grid=param_grid,\n    cv=10,\n    scoring=\"neg_mean_squared_error\",\n    n_jobs=-1\n)\n\ngrid.fit(X_train_s, y_train)\n\ngrid.best_params_\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```\n{'alpha': 5e-05, 'hidden_layer_sizes': (5,), 'solver': 'lbfgs'}\n```\n:::\n:::\n\n\n::: {#6f53ac1e .cell execution_count=6}\n``` {.python .cell-code}\nbest_model = grid.best_estimator_\npred_gs = best_model.predict(X_test_s)\n\nrmse_gs = mean_squared_error(y_test, pred_gs) ** 0.5\nrmse_gs\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\n39176.951700141195\n```\n:::\n:::\n\n\n",
    "supporting": [
      "nn1-python_files/figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}