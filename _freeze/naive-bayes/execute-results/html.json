{
  "hash": "fe761ff7179b427cfd67c783232fdd48",
  "result": {
    "engine": "knitr",
    "markdown": "\n---\ntitle: \"Naive Bayes Classification R version\"\nformat:\n  html:\n    toc: true\n    toc-depth: 3\n    code-fold: true\nexecute:\n  echo: true\n  warning: false\n  message: false\n---\n\n## 1. Overview and Learning Objectives\n\nIn this chapter, we will:\n\n1. Use the **Ames Housing** data to create a **binary classification** problem:\n   - Predict whether a house is **high price** vs **low price** based on its features..\n2. Understand how Naive Bayes handles:\n   - **Categorical vs numeric** predictors  \n   - **Laplace correction** (additive smoothing)  \n   - **Kernel density estimation** for numeric variables  \n3. Use **caret** (`train(method = \"nb\")`) to:\n   - **Tune** key hyperparameters (`usekernel`, `fL`)\n   - Evaluate performance with **cross-validation**\n4. Interpret:\n   - Class priors  \n   - Conditional feature distributions  \n   - Predictions & confusion matrix  \n   - ROC curve and AUC\n\n---\n\n## 2. Data Setup and Binary Target Creation\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(caret)\nlibrary(AmesHousing)\nlibrary(pROC)\n\nset.seed(4321)\n\names <- make_ordinal_ames() %>% mutate(id = row_number())\n\ntraining <- ames %>% sample_frac(0.7)\ntesting  <- anti_join(ames, training, by = \"id\")\n\npredictors <- c(\n  \"Sale_Price\",\"Bedroom_AbvGr\",\"Year_Built\",\"Mo_Sold\",\"Lot_Area\",\n  \"Street\",\"Central_Air\",\"First_Flr_SF\",\"Second_Flr_SF\",\"Full_Bath\",\n  \"Half_Bath\",\"Fireplaces\",\"Garage_Area\",\"Gr_Liv_Area\",\"TotRms_AbvGrd\"\n)\n\ntraining <- training %>% select(all_of(predictors))\ntesting  <- testing %>% select(all_of(predictors))\n```\n:::\n\n\nWe turn `Sale_Price` into a **classification target**:\n\n- `\"High\"` if above the training-set median  \n- `\"Low\"` otherwise  \n\nThis keeps the task aligned with Naive Bayes as a **classification** model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprice_median <- median(training$Sale_Price)\n\ntraining <- training %>% mutate(Price_High = factor(ifelse(Sale_Price > price_median,\"High\",\"Low\")))\ntesting  <- testing  %>% mutate(Price_High = factor(ifelse(Sale_Price > price_median,\"High\",\"Low\")))\n\ntraining_nb <- training %>% select(-Sale_Price)\ntesting_nb  <- testing  %>% select(-Sale_Price)\n```\n:::\n\n\n---\n\n## 3. Naive Bayes Intuition\n\nNaive Bayes is a **generative classifier** based on Bayes’ theorem:\n\n\\[\nP(Y = k \\mid X) \\propto P(Y=k) \\prod_{j=1}^p P(x_j \\mid Y=k)\n\\]\n\nKey assumptions:\n\n#### **1. Conditional Independence**\nGiven the class, features are treated as independent:\n\n\\[\nP(x_1, x_2, \\dots, x_p \\mid Y=k)\n\\approx \\prod_j P(x_j \\mid Y=k)\n\\]\n\nThis is rarely exactly true, yet often works surprisingly well.\n\n#### **2. Modeling Numeric Features**\nNaive Bayes supports two approaches:\n\n- **Gaussian (Normal):** assumes each numeric feature is normally distributed within each class.  \n- **Kernel Density Estimation:** more flexible, handles skewness and multimodal distributions.\n\n#### **3. Laplace Correction**\nPrevents zero probabilities when a category never appears in a given class:\n\n'''text\nP(x=v | Y=k) = (count + 1) / (N + K)\n'''\n\nThis keeps the model from collapsing.\n\n---\n\n## 4. Fitting Naive Bayes (Baseline Model)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(12345)\n\nnb.ames <- naiveBayes(\n  Price_High ~ ., \n  data = training_nb,\n  laplace = 0,\n  usekernel = TRUE\n)\n\nnb.ames\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nNaive Bayes Classifier for Discrete Predictors\n\nCall:\nnaiveBayes.default(x = X, y = Y, laplace = laplace, usekernel = TRUE)\n\nA-priori probabilities:\nY\n     High       Low \n0.4987811 0.5012189 \n\nConditional probabilities:\n      Bedroom_AbvGr\nY          [,1]      [,2]\n  High 2.948192 0.8218245\n  Low  2.770428 0.8207514\n\n      Year_Built\nY          [,1]     [,2]\n  High 1989.604 23.12763\n  Low  1953.780 25.88135\n\n      Mo_Sold\nY          [,1]     [,2]\n  High 6.353861 2.732694\n  Low  6.157588 2.691989\n\n      Lot_Area\nY           [,1]      [,2]\n  High 11726.913 10345.651\n  Low   8673.011  4673.732\n\n      Street\nY              Grvl         Pave\n  High 0.0009775171 0.9990224829\n  Low  0.0058365759 0.9941634241\n\n      Central_Air\nY                N           Y\n  High 0.008797654 0.991202346\n  Low  0.122568093 0.877431907\n\n      First_Flr_SF\nY           [,1]     [,2]\n  High 1333.7087 408.4059\n  Low   986.6527 264.8090\n\n      Second_Flr_SF\nY          [,1]     [,2]\n  High 447.7625 493.0434\n  Low  222.7490 317.7090\n\n      Full_Bath\nY          [,1]      [,2]\n  High 1.913001 0.4415516\n  Low  1.233463 0.4412614\n\n      Half_Bath\nY           [,1]      [,2]\n  High 0.5259042 0.5168999\n  Low  0.2324903 0.4406718\n\n      Fireplaces\nY           [,1]      [,2]\n  High 0.8670577 0.6271108\n  Low  0.3180934 0.5359368\n\n      Garage_Area\nY          [,1]     [,2]\n  High 581.0430 173.7891\n  Low  362.3016 190.0580\n\n      Gr_Liv_Area\nY          [,1]     [,2]\n  High 1783.837 473.5654\n  Low  1215.255 342.4179\n\n      TotRms_AbvGrd\nY          [,1]     [,2]\n  High 7.043988 1.516711\n  Low  5.825875 1.373640\n```\n\n\n:::\n:::\n\n\n#### Explanation of key settings\n\n- **laplace = 0**  \n  No smoothing; probability estimates reflect raw counts.  \n  Zero probabilities may occur for rare categorical levels.\n\n- **usekernel = TRUE**  \n  Numeric features are modeled using **kernel density estimates** instead of assuming normality.\n\n#### What the output means\n\n- **A-priori probabilities:**  \n  Estimated from class frequencies (High vs Low).\n\n- **Conditional tables:**  \n  - For categorical features: probability of each level given class.  \n  - For numerical features: kernel-based density info (not printed in summary).\n\n---\n\n## 5. Predicting on Test Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest_pred_class <- predict(nb.ames, testing_nb)\ntest_pred_prob  <- predict(nb.ames, testing_nb, type=\"raw\")\nhead(test_pred_prob)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          High          Low\n[1,] 0.9999965 3.462116e-06\n[2,] 0.9850961 1.490391e-02\n[3,] 0.9830462 1.695380e-02\n[4,] 0.5936144 4.063856e-01\n[5,] 0.9437367 5.626333e-02\n[6,] 0.9998253 1.746816e-04\n```\n\n\n:::\n:::\n\n\n- `test_pred_class`: predicted High/Low label  \n- `test_pred_prob`: estimated probability for each class\n\n---\n\n## 6. Confusion Matrix Interpretation\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconf_matrix <- confusionMatrix(\n  test_pred_class,\n  testing_nb$Price_High,\n  positive=\"High\"\n)\n\nconf_matrix\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction High Low\n      High  373  49\n      Low    55 402\n                                          \n               Accuracy : 0.8817          \n                 95% CI : (0.8585, 0.9023)\n    No Information Rate : 0.5131          \n    P-Value [Acc > NIR] : <2e-16          \n                                          \n                  Kappa : 0.7631          \n                                          \n Mcnemar's Test P-Value : 0.6239          \n                                          \n            Sensitivity : 0.8715          \n            Specificity : 0.8914          \n         Pos Pred Value : 0.8839          \n         Neg Pred Value : 0.8796          \n             Prevalence : 0.4869          \n         Detection Rate : 0.4243          \n   Detection Prevalence : 0.4801          \n      Balanced Accuracy : 0.8814          \n                                          \n       'Positive' Class : High            \n                                          \n```\n\n\n:::\n:::\n\n\n#### What the confusion matrix tells us\n\n- **Accuracy**: overall correctness  \n- **Sensitivity (Recall for High)**: proportion of expensive homes correctly identified  \n- **Specificity (Recall for Low)**: proportion of cheaper homes correctly identified  \n- **Balanced Accuracy**: average of sensitivity & specificity  \n- **Kappa**: agreement beyond chance  \n\nThis is the primary evaluation for classification problems.\n\n---\n\n## 7. ROC Curve & AUC\n\nROC curves evaluate model ranking ability — how well it separates High from Low across thresholds.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nroc_obj <- roc(\n  response = testing_nb$Price_High,\n  predictor = test_pred_prob[,\"High\"],\n  levels = c(\"Low\",\"High\")\n)\n\nplot(roc_obj, col=\"#2E86C1\", lwd=3, main=\"ROC Curve - Naive Bayes\")\n```\n\n::: {.cell-output-display}\n![](naive-bayes_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n\n```{.r .cell-code}\nauc_value <- auc(roc_obj)\nauc_value\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nArea under the curve: 0.9457\n```\n\n\n:::\n:::\n\n\n#### Interpretation\n\n- **ROC Curve:** visual representation of sensitivity vs (1 - specificity)  \n- **AUC:** single summary metric  \n  - 0.5 = no better than random  \n  - 0.7 = decent  \n  - 0.8 = strong  \n  - >0.9 = outstanding  \n\n---\n\n## 8. Tuning Naive Bayes Using `caret::train()`\n\nWe now tune:\n\n- `usekernel` ∈ {TRUE, FALSE}  \n- `fL` ∈ {0, 0.5, 1} *(fractional Laplace)*  \n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(12345)\n\ntune_grid <- expand.grid(\n  usekernel = c(TRUE, FALSE),\n  fL        = c(0, 0.5, 1),\n  adjust    = 1\n)\n\nctrl <- trainControl(\n  method = \"cv\",\n  number = 10,\n  classProbs = TRUE,\n  summaryFunction = twoClassSummary\n)\n\ntraining_nb$Price_High <- relevel(training_nb$Price_High, ref=\"High\")\ntesting_nb$Price_High  <- relevel(testing_nb$Price_High, ref=\"High\")\n\nnb.ames.caret <- train(\n  Price_High ~ .,\n  data = training_nb,\n  method = \"nb\",\n  tuneGrid = tune_grid,\n  trControl = ctrl,\n  metric =\"ROC\"\n)\n\nnb.ames.caret\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNaive Bayes \n\n2051 samples\n  14 predictor\n   2 classes: 'High', 'Low' \n\nNo pre-processing\nResampling: Cross-Validated (10 fold) \nSummary of sample sizes: 1845, 1846, 1846, 1846, 1846, 1845, ... \nResampling results across tuning parameters:\n\n  usekernel  fL   ROC        Sens       Spec     \n  FALSE      0.0  0.9325587  0.9217484  0.8453794\n  FALSE      0.5  0.9325587  0.9217484  0.8453794\n  FALSE      1.0  0.9325587  0.9217484  0.8453794\n   TRUE      0.0  0.9549057  0.9197316  0.8589473\n   TRUE      0.5  0.9549057  0.9197316  0.8589473\n   TRUE      1.0  0.9549057  0.9197316  0.8589473\n\nTuning parameter 'adjust' was held constant at a value of 1\nROC was used to select the optimal model using the largest value.\nThe final values used for the model were fL = 0, usekernel = TRUE and adjust\n = 1.\n```\n\n\n:::\n:::\n\n\n###$ How tuning works\n\n- **Cross-validation** evaluates each combination of hyperparameters.  \n- Best model chosen by the metric (`ROC`).  \n- caret automatically handles class probabilities and ROC scoring.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnb.ames.caret$results\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  usekernel  fL adjust       ROC      Sens      Spec      ROCSD     SensSD\n1     FALSE 0.0      1 0.9325587 0.9217484 0.8453794 0.02290800 0.03508486\n4      TRUE 0.0      1 0.9549057 0.9197316 0.8589473 0.01199907 0.04510391\n2     FALSE 0.5      1 0.9325587 0.9217484 0.8453794 0.02290800 0.03508486\n5      TRUE 0.5      1 0.9549057 0.9197316 0.8589473 0.01199907 0.04510391\n3     FALSE 1.0      1 0.9325587 0.9217484 0.8453794 0.02290800 0.03508486\n6      TRUE 1.0      1 0.9549057 0.9197316 0.8589473 0.01199907 0.04510391\n      SpecSD\n1 0.02659457\n4 0.03971772\n2 0.02659457\n5 0.03971772\n3 0.02659457\n6 0.03971772\n```\n\n\n:::\n\n```{.r .cell-code}\nnb.ames.caret$bestTune\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  fL usekernel adjust\n4  0      TRUE      1\n```\n\n\n:::\n\n```{.r .cell-code}\nplot(nb.ames.caret)\n```\n\n::: {.cell-output-display}\n![](naive-bayes_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n---\n\n## 9. Evaluating the Tuned Model on the Test Set\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest_pred_class_tuned <- predict(nb.ames.caret, testing_nb)\ntest_pred_prob_tuned <- predict(nb.ames.caret, testing_nb, type=\"prob\")\n\nconfusionMatrix(\n  test_pred_class_tuned,\n  testing_nb$Price_High,\n  positive=\"High\"\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction High Low\n      High  398  77\n      Low    30 374\n                                          \n               Accuracy : 0.8783          \n                 95% CI : (0.8548, 0.8992)\n    No Information Rate : 0.5131          \n    P-Value [Acc > NIR] : < 2.2e-16       \n                                          \n                  Kappa : 0.7571          \n                                          \n Mcnemar's Test P-Value : 8.708e-06       \n                                          \n            Sensitivity : 0.9299          \n            Specificity : 0.8293          \n         Pos Pred Value : 0.8379          \n         Neg Pred Value : 0.9257          \n             Prevalence : 0.4869          \n         Detection Rate : 0.4528          \n   Detection Prevalence : 0.5404          \n      Balanced Accuracy : 0.8796          \n                                          \n       'Positive' Class : High            \n                                          \n```\n\n\n:::\n:::\n\n\n---\n\n## 10. Summary\n\n- Naive Bayes is a **probabilistic, generative classifier**.  \n- It models **class priors** + **conditional likelihoods** for each predictor.  \n- Numeric predictors can use:\n  - **Gaussian distributions**, or  \n  - **Kernel density estimates** (`usekernel = TRUE`).  \n- **Laplace smoothing** protects against zero probabilities.  \n- **ROC** and **AUC** evaluate ranking performance.  \n- **Confusion matrix** evaluates classification performance.  \n- **caret** enables systematic tuning over smoothing and density options.\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}