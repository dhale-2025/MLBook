---
title: "Neural Networks in R"
format:
  html:
    toc: true
    code-fold: true
  pdf:
    toc: true
execute:
  echo: true
  warning: false
  message: false
---

## Introduction

This chapter introduces **neural networks in R**, progressing from feed-forward to recurrent (RNN) and convolutional (CNN) architectures.\
It uses the Ames housing dataset, a sine wave sequence, and the MNIST digit dataset to demonstrate increasingly complex network structures.

Each example illustrates a different ANN architecture.

------------------------------------------------------------------------

## 1. Feed-Forward Neural Networks (Ames Data)

Feed-forward networks are the simplest type of neural networks. They map input features (like home size, rooms, or year built) to an output (home price) through **layers of neurons**.\
Each neuron applies a weighted sum and activation function, allowing the network to learn complex relationships between variables.

```{r}
#Note: This is specific to my environment 
library(reticulate)
use_python("/Users/donaldhale/r-arm/bin/python", required = TRUE)

library(keras3)

tf <- reticulate::import("tensorflow", delay_load = FALSE)
cat("TensorFlow version:", tf$`__version__`, "\n")
```



```{r}
library(tidyverse)
library(caret)
library(nnet)
library(NeuralNetTools)
library(AmesHousing)

set.seed(4321)

# Load and sample data
ames <- make_ordinal_ames() %>% mutate(id = row_number())
train_idx <- sample(1:nrow(ames), 0.7 * nrow(ames))
training <- ames[train_idx, ]
testing  <- ames[-train_idx, ]

# Select a manageable subset of variables
vars <- c("Sale_Price", "Bedroom_AbvGr", "Year_Built", "Mo_Sold", "Lot_Area",
          "Street", "Central_Air", "First_Flr_SF", "Second_Flr_SF",
          "Full_Bath", "Half_Bath", "Fireplaces", "Garage_Area",
          "Gr_Liv_Area", "TotRms_AbvGrd")
training <- training[, vars]
testing  <- testing[, vars]

# Convert categorical predictors into dummy numeric columns
x_train <- model.matrix(Sale_Price ~ ., data = training)[, -1]
y_train <- training$Sale_Price
x_test  <- model.matrix(Sale_Price ~ ., data = testing)[, -1]
y_test  <- testing$Sale_Price

# Drop low-variance predictors and scale for stable training
nzv <- nearZeroVar(x_train)
if (length(nzv) > 0) {
  x_train <- x_train[, -nzv, drop = FALSE]
  x_test  <- x_test[, -nzv, drop = FALSE]
}

x_train <- scale(x_train)
x_test  <- scale(x_test, center = attr(x_train, "scaled:center"),
                 scale = attr(x_train, "scaled:scale"))

y_train_s <- scale(y_train)

# Combine into a single training dataframe
train_df <- data.frame(y = as.numeric(y_train_s), x_train)

set.seed(123)
nn.ames <- nnet(y ~ ., data = train_df, size = 5, linout = TRUE, trace = FALSE)
plotnet(nn.ames)
```

------------------------------------------------------------------------

### 1.2 Cross-Validation Tuning

We tune two important parameters: - **`size`** — number of neurons in the hidden layer\
- **`decay`** — regularization strength (prevents overfitting)

`caret::train()` automates this search using k-fold cross-validation.

```{r}
tune_grid <- expand.grid(size = c(3,5,7,9), decay = c(0,0.1,0.5,1))
ctrl <- trainControl(method = "cv", number = 5)

set.seed(123)
nn.tuned <- train(
  x = x_train, y = as.numeric(y_train_s),
  method = "nnet",
  tuneGrid = tune_grid,
  trControl = ctrl,
  linout = TRUE,
  trace = FALSE
)

nn.tuned$bestTune
plot(nn.tuned)
```

------------------------------------------------------------------------

### 1.3 Evaluate Performance

After identifying the best parameters, we retrain the model and evaluate its predictive accuracy.

```{r}
best_size  <- nn.tuned$bestTune$size
best_decay <- nn.tuned$bestTune$decay

set.seed(123)
nn.final <- nnet(
  y ~ ., 
  data = train_df, 
  size = best_size, 
  decay = best_decay, 
  linout = TRUE, 
  trace = FALSE
)

pred_std <- predict(nn.final, newdata = as.data.frame(x_test))
pred_nn  <- pred_std * attr(y_train_s, "scaled:scale") + attr(y_train_s, "scaled:center")

perf <- data.frame(
  MAE  = mean(abs(y_test - pred_nn)),
  MAPE = mean(abs((y_test - pred_nn) / y_test)) * 100
)
perf
```

------------------------------------------------------------------------

## 2. Feed-Forward Neural Networks (Keras 3)

The **Keras 3** API is a modern deep learning interface. It supports more complex models and GPUs while maintaining a simple syntax.\
This example shows the same concept as above using a multi-layer perceptron (MLP).

```{r}
#library(keras3)
set.seed(123)

model_ff <- keras_model_sequential() |>
  layer_dense(units = 16, activation = "relu", input_shape = ncol(x_train)) |>
  layer_dropout(rate = 0.1) |>
  layer_dense(units = 1)

compile(model_ff, optimizer = optimizer_adam(learning_rate = 0.01),
        loss = "mse", metrics = "mae")

history <- fit(model_ff, x_train, as.numeric(y_train_s),
               epochs = 40, batch_size = 32, validation_split = 0.2, verbose = 0)

plot(history)
```

------------------------------------------------------------------------

## 3. Recurrent Neural Network (RNN)

RNNs are ideal for **sequential data** such as time series, text, or speech.\
We use a sine wave as a toy example because its repeating pattern requires the model to “remember” recent values — something feed-forward networks cannot do.

```{r}
set.seed(42)
t <- seq(0, 50, by = 0.1)
y <- sin(t)
plot(t, y, type='l', main="Sine Wave Example", ylab="y", xlab="Time")

window_size <- 20
X <- sapply(1:(length(y) - window_size), function(i) y[i:(i + window_size - 1)])
X <- t(X)
y_out <- y[(window_size + 1):length(y)]
X <- array(X, dim = c(nrow(X), window_size, 1))

split <- round(0.8 * nrow(X))
x_train <- X[1:split,,]; y_train <- y_out[1:split]
x_test  <- X[(split + 1):nrow(X),,]; y_test  <- y_out[(split + 1):length(y_out)]

model_rnn <- keras_model_sequential() |>
  layer_simple_rnn(units = 16, activation = "tanh", input_shape = c(window_size, 1)) |>
  layer_dense(units = 1)

compile(model_rnn, loss = "mse", optimizer = "adam")

history_rnn <- fit(model_rnn, x_train, y_train, epochs = 30, batch_size = 16,
                   validation_split = 0.2, verbose = 0)

plot(history_rnn)
preds <- predict(model_rnn, x_test)

plot(y_test, type='l', main="RNN Sine Prediction", col='blue', ylab="y")
lines(preds, col='red')
legend("bottomleft", legend=c("Actual","Predicted"), col=c("blue","red"), lty=1, bty="n")
```

------------------------------------------------------------------------

## 4. Convolutional Neural Network (CNN)

CNNs are built for **spatial pattern recognition** — ideal for images.\
The **MNIST** dataset contains 70,000 grayscale images of handwritten digits (0–9), each 28×28 pixels.\
These lines prepare the data for use in a CNN.

```{r}
#library(keras3)

# Load and preview the MNIST data
mnist <- dataset_mnist()

# We only use a subset (5k train, 1k test) for quick demonstration
x_train <- mnist$train$x[1:5000,,]
y_train <- mnist$train$y[1:5000]
x_test  <- mnist$test$x[1:1000,,]
y_test  <- mnist$test$y[1:1000]

# Normalize pixel values: 0-255 -> 0-1
x_train <- x_train / 255
x_test  <- x_test / 255

# Reshape to [samples, height, width, channels]
# MNIST images are grayscale, so channels = 1
x_train <- array_reshape(x_train, c(nrow(x_train), 28, 28, 1))
x_test  <- array_reshape(x_test,  c(nrow(x_test),  28, 28, 1))

# Convert labels to categorical one-hot vectors (10 classes for digits 0-9)
y_train_cat <- to_categorical(y_train, 10)
y_test_cat  <- to_categorical(y_test, 10)
```

### Explanation of the MNIST Preprocessing

1.  **Load** the built-in dataset from Keras.\
2.  **Subsample** for faster training (5,000 train / 1,000 test).\
3.  **Normalize** pixel intensities to the 0–1 range.\
4.  **Reshape** to the 4D structure required by CNNs: `[samples, height, width, channels]`.\
5.  **One-hot encode** labels, converting a digit like `3` into a vector `[0,0,0,1,0,0,0,0,0,0]`.

These steps turn raw pixel data into numeric tensors suitable for learning.

------------------------------------------------------------------------

### 4.1 Train and Evaluate the CNN

```{r}
model_cnn <- keras_model_sequential() |>
  layer_conv_2d(filters = 16, kernel_size = c(3,3), activation = "relu", input_shape = c(28,28,1)) |>
  layer_max_pooling_2d(pool_size = c(2,2)) |>
  layer_flatten() |>
  layer_dense(units = 32, activation = "relu") |>
  layer_dense(units = 10, activation = "softmax")

compile(model_cnn, optimizer = "adam",
        loss = "categorical_crossentropy",
        metrics = "accuracy")

history_cnn <- fit(model_cnn, x_train, y_train_cat,
                   epochs = 3, batch_size = 64, validation_split = 0.2, verbose = 0)

plot(history_cnn)
score <- evaluate(model_cnn, x_test, y_test_cat)
score
```

------------------------------------------------------------------------

### 4.2 Visualizing Correct and Incorrect Predictions

We visualize examples of digits that the CNN classified correctly and incorrectly.

```{r}
pred_probs <- predict(model_cnn, x_test)
pred_classes <- apply(pred_probs, 1, which.max) - 1

correct_idx <- which(pred_classes == y_test)[1:6]
incorrect_idx <- which(pred_classes != y_test)[1:6]

par(mfrow=c(2,6), mar=c(1,1,2,1))
for (i in correct_idx) {
  img <- x_test[i,,,1]
  image(1:28, 1:28, t(apply(img, 2, rev)), col=gray.colors(255), axes=FALSE,
        main=paste("✓", y_test[i]))
}
for (i in incorrect_idx) {
  img <- x_test[i,,,1]
  image(1:28, 1:28, t(apply(img, 2, rev)), col=gray.colors(255), axes=FALSE,
        main=paste("✗", y_test[i], "→", pred_classes[i]))
}
```

------------------------------------------------------------------------

## Summary

-   **Feed-forward networks**: handle static, tabular data (e.g., housing prices).\
-   **RNNs**: handle sequential data with temporal dependencies (e.g., sine wave, stock prices, text, timer series).\
-   **CNNs**: handle image and spatial data by learning patterns like edges and textures.

